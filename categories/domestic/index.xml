<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>domestic on urushiyamaのさまつごと</title>
    <link>https://urushiyama.github.io/categories/domestic/</link>
    <description>Recent content in domestic on urushiyamaのさまつごと</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>&amp;copy; 2018-2021 urushiyama | Powered by [Hugo](https://gohugo.io) with [HUCORE](https://themes.gohugo.io/hucore/) theme.</copyright>
    <lastBuildDate>Wed, 11 Dec 2019 15:20:00 +0900</lastBuildDate><atom:link href="https://urushiyama.github.io/categories/domestic/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>スマートフォンにおける押下圧によるタップの拡張のための予備調査（HCI185）</title>
      <link>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci185co/</link>
      <pubDate>Wed, 11 Dec 2019 15:20:00 +0900</pubDate>
      
      <guid>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci185co/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.iplab.cs.tsukuba.ac.jp/~ikeda/&#34;&gt;主著のWebページへ&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;スマートフォンにおける限られた入力語彙を拡張するために，我々は押下圧によるタップの複数種類への拡張手法を提案する．提案手法はタップ時にスマートフォン搭載感圧センサから取得される最大の押下圧をタップの強さとし，その強さをもとにタップを 3 種類以上に拡張する．本研究では提案手法の実装に先立ち，スマートフォンにおいてユーザがタップの強さを調節可能な精度を明らかにするための予備実験を行った．システムが取得可能な押下圧の範囲を線形に 2-6 分割したうちのある一領域に対してタップの強さを調節する分割タスクでは，2 分割においては 98.1%，6 分割においては 54.0% のタスク成功率であった．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>画面拡張時におけるミラーリング領域の表示方法に関する比較調査（HCI185）</title>
      <link>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci185/</link>
      <pubDate>Tue, 10 Dec 2019 16:25:00 +0900</pubDate>
      
      <guid>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci185/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;我々は，ディスプレイを見ながらのスマートフォン上での操作を可能にし，かつディスプレイ全域にてコンテンツを閲覧可能にすることを目的とした，外部ディスプレイを用いたスマートフォンの画面拡張手法を提案している．提案手法は，スマートフォンの表示をそのままディスプレイに映し，さらにスマートフォンの画面に収まらないコンテンツをその外側に表示することにより探索を必要とする作業を速めることが示唆されている．ただし，我々の画面拡張手法には，様々な設計要素が存在する．本研究にて，我々はこれらの設計要素のうち，ミラーリング領域を示す表示方法として検討した 4 種を用いる場合のターゲット選択性能およびユーザビリティを比較する実験を行った．その結果，ミラーリング領域を示す枠を何も表示しない方法を採用すべきでないことがわかった．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>外部ディスプレイを用いたスマートフォンの画面拡張手法の予備調査（WISS2019）</title>
      <link>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-poster/wiss2019proceedings/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0900</pubDate>
      
      <guid>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-poster/wiss2019proceedings/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;スマートフォンと接続されたディスプレイにコンテンツを表示させる手法として，ミラーリングとキャスティングがある．
ミラーリングでは，ディスプレイ上にスマートフォンの画面に表示されるコンテンツのみが表示され，キャスティングでは，スマートフォン上のみに専用のGUIが表示されるためディスプレイを見ながらのスマートフォン上での操作に困難が伴う．
我々は，ディスプレイを見ながらのスマートフォン上での操作を可能にし，かつディスプレイ全域にてコンテンツを閲覧可能にする，外部ディスプレイを用いたスマートフォンの画面拡張手法を提案する．
提案手法は，スマートフォンの表示をそのままディスプレイに映し，さらにスマートフォンの画面に収まらないコンテンツをその外側に表示する．
探索に対する提案手法の効果を調査した結果，提案手法は探索を必要とする作業を速めることが示唆された．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>異なる手形状に対する周波数応答の予備調査（HCI184）</title>
      <link>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci184/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci184/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;実世界の状態識別を行うための手法の一つに，物体に与えた音響信号の周波数応答を解析するアクティブ音響センシングがある．この手法はハンドジェスチャ認識のための手形状の識別にも適用することが可能である．本研究では，異なる手形状に対して顕著な応答が得られる周波数を明らかにするため，範囲の異なる複数のスイープ信号に対する周波数応答を調べた．実験により得られた周波数応答のスペクトルに関して，送波したスイープ信号毎のピークに対する観察および機械学習による手形状のクラス識別精度に対する分析を行った結果，24kHz-48kHz にて手形状，実験参加者，およびタスク間における際立った差異が観察され，16kHz-32kHz，24kHz-40kHz，および 32kHz-48kHz のスイープ信号を送波した際のクラス識別率が高いことが明らかになった．したがって，16kHz-48kHz の中に，手形状に対して顕著な応答が得られる周波数が存在する可能性が高い．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>指の軌跡に基づくモバイル端末向けアイズフリーかな文字入力の提案（HCI181）</title>
      <link>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci181/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0900</pubDate>
      
      <guid>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-oral/hci181/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;アイズフリー文字入力は，周囲に視覚的注意が必要とされる状況において，モバイル端末のスクリーンへの視認を不要にするため，有用である．しかしながら，手元を視認せずに行われるタッチ操作は粗いため，堅牢な文字入力手法が求められる．そこで我々は，タッチ開始位置を中心とする5領域を一筆書きにて通過するのみにより，1文字の子音および母音の双方を入力可能なかな文字入力手法を提案する．今回我々は，スマートフォンおよびスマートウォッチ上で動作する提案手法のプロトタイプシステムを実装した．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>指の軌跡に基づく手元の視認が不要なスマートフォン向けかな文字入力手法（WISS2018）</title>
      <link>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-poster/wiss2018proceedings/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0900</pubDate>
      
      <guid>https://urushiyama.github.io/publications/non-peer-reviewed-domestic-poster/wiss2018proceedings/</guid>
      <description>&lt;h2 id=&#34;概要&#34;&gt;概要&lt;/h2&gt;
&lt;p&gt;手元を見ずにスマートフォンによる文字入力が行えれば，ユーザは歩行中あるいは会話中にスマートフォンにてメモを取ることができる．しかし，視覚以外の感覚によりタッチ位置をタッチ前に知覚することは困難であるため，キーを視認する必要がある．
我々は文字入力時に手元の視認が不要な，指の軌跡に基づくスマートフォン向けのかな文字入力手法を提案する．
提案手法は，タッチ位置を基点とする円形領域および外側の上下左右4方向の領域を指が一筆書きにて通過する順序に基づいて，文字の子音および母音を決定するため，正確さの粗いタッチ操作に対して堅牢な文字入力が期待される．&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
